{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "# openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "OPENAI_API_KEY='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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This example works. \n",
    "- Needs GPT-4 to get concise strings as responses. Minor prompt meddling to read year from context.\n",
    "- Next is the difficult (meta) step, to generate these JSON objects from the company's description.\n",
    "- Applying regex validation rather than a manager prompt works consistently for int and float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The JSON structure contains prefilled values for query and validation steps. \n",
    "# In principle we want these to be generated (and validated) by the meta function.\n",
    "\n",
    "json_data = {\n",
    "  \"items\": {\n",
    "    \"diverse_csuite\": {\n",
    "    \"prefilled_prompt_template\": \"Use the context below to provide the percentage of C-suite individuals over 50 who participate in the DEI programme as a float with nothing else. If the answer is not in the context, output 'Null':\",\n",
    "    \"unit\": \"%\",\n",
    "    \"validation\": \"\\\\b\\\\d*\\\\.?\\\\d+\\\\b\",\n",
    "    \"output\": {\n",
    "      \"value\": None\n",
    "    }\n",
    "  },\n",
    "    \"workforce_count_start\": {\n",
    "      \"prefilled_prompt_template\": \"Use the context below to find the year the workforce counting policy began. Return the year with nothing else. If the answer is not in the context, output 'Null':\",\n",
    "      \"unit\": \"year\",\n",
    "      \"validation\": \"\\b(?:19|20)\\d{2}\\b\",\n",
    "      \"output\": {\n",
    "        \"value\": None\n",
    "      }\n",
    "    },\n",
    "    \"num_hispanic_managers\": {\n",
    "      \"prefilled_prompt_template\": \"Use the context below to provide total hispanic managers as an integer with nothing else. If the answer is not in the context, output 'Null':\",\n",
    "      \"unit\":\"int\",\n",
    "      \"validation\": \"\\\\b\\\\d+\\\\b\",\n",
    "      \"output\": {\n",
    "        \"value\": None\n",
    "      }\n",
    "    },\n",
    "    \"dynamics_measures\": {\n",
    "      \"prefilled_prompt_template\": \"What measures have been taken to improve workforce dynamics? Provide a 1-5 word answer with nothing else. If the answer is not in the context, output 'Null':\",\n",
    "      \"unit\":\"string\",\n",
    "      \"validation\": \"5w_or_less\",\n",
    "      \"output\": {\n",
    "        \"value\": None\n",
    "      }\n",
    "    }\n",
    "}}\n",
    "\n",
    "file_path = '/Users/cardigan/Documents/Small_Projects/tesla.md'\n",
    "with open(file_path, 'r') as file:\n",
    "    tesla = file.read()\n",
    "\n",
    "doc_list = [tesla, \"diverse_csuite\", \"workforce_count_start\", \"num_hispanic_managers\", \"dynamics_measures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: \n",
      "\n",
      "72.4\n",
      "response: \n",
      "\n",
      "Null\n",
      "response: \n",
      "\n",
      "20\n",
      "response: Implementing social change policies\n",
      "{\n",
      "    \"items\": {\n",
      "        \"diverse_csuite\": {\n",
      "            \"prefilled_prompt_template\": \"Use the context below to provide the percentage of C-suite individuals over 50 who participate in the DEI programme as a float with nothing else. If the answer is not in the context, output 'Null':\",\n",
      "            \"unit\": \"%\",\n",
      "            \"validation\": \"\\\\b\\\\d*\\\\.?\\\\d+\\\\b\",\n",
      "            \"output\": {\n",
      "                \"value\": \"72.4\"\n",
      "            }\n",
      "        },\n",
      "        \"workforce_count_start\": {\n",
      "            \"prefilled_prompt_template\": \"Use the context below to find the year the workforce counting policy began. Return the year with nothing else. If the answer is not in the context, output 'Null':\",\n",
      "            \"unit\": \"year\",\n",
      "            \"validation\": \"\\b(?:19|20)\\\\d{2}\\b\",\n",
      "            \"output\": {\n",
      "                \"value\": \"Null\"\n",
      "            }\n",
      "        },\n",
      "        \"num_hispanic_managers\": {\n",
      "            \"prefilled_prompt_template\": \"Use the context below to provide total hispanic managers as an integer with nothing else. If the answer is not in the context, output 'Null':\",\n",
      "            \"unit\": \"int\",\n",
      "            \"validation\": \"\\\\b\\\\d+\\\\b\",\n",
      "            \"output\": {\n",
      "                \"value\": \"20\"\n",
      "            }\n",
      "        },\n",
      "        \"dynamics_measures\": {\n",
      "            \"prefilled_prompt_template\": \"What measures have been taken to improve workforce dynamics? Provide a 1-5 word answer with nothing else. If the answer is not in the context, output 'Null':\",\n",
      "            \"unit\": \"string\",\n",
      "            \"validation\": \"5w_or_less\",\n",
      "            \"output\": {\n",
      "                \"value\": \"Implementing social change policies\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Function to retrieve prefilled prompt template\n",
    "def get_prefilled_prompt(json_data, var_name):\n",
    "    if var_name in json_data[\"items\"]:\n",
    "        return json_data[\"items\"][var_name][\"prefilled_prompt_template\"], json_data[\"items\"][var_name][\"validation\"], json_data[\"items\"][var_name][\"unit\"]\n",
    "    print(f\"No template or validation found for var_name: {var_name}\")\n",
    "    return None, None, None\n",
    "\n",
    "# Function to process the input and store the result\n",
    "def process_input(doc_list, json_data):\n",
    "    var_names = doc_list[1:]\n",
    "    for var_name in var_names:\n",
    "        prefilled_template, validation, unit = get_prefilled_prompt(json_data, var_name)\n",
    "        if prefilled_template and validation:\n",
    "            # Concatenate the template with doc_text\n",
    "            full_prompt = f\"{prefilled_template} \\n{doc_list[0]}\"  # Assuming first item in doc_list is the document\n",
    "            # print(\"full_prompt:\", full_prompt[:100])\n",
    "\n",
    "            # use GPT-3.5t for number responses\n",
    "            if unit in ['%', 'int', 'year']:\n",
    "                model = OpenAI()\n",
    "                response = model.invoke(full_prompt)\n",
    "                print(\"response:\", response)\n",
    "                match = re.search(validation, response)\n",
    "                if match:\n",
    "                    json_data[\"items\"][var_name][\"output\"][\"value\"] = match.group()\n",
    "                else:\n",
    "                    json_data[\"items\"][var_name][\"output\"][\"value\"] = \"Null\"\n",
    "\n",
    "            # Need GPT4 for strings\n",
    "            elif unit == \"string\":\n",
    "                model = ChatOpenAI(model_name=\"gpt-4\")\n",
    "                response = model.invoke(full_prompt).content\n",
    "                print(\"response:\", response)\n",
    "                json_data[\"items\"][var_name][\"output\"][\"value\"] = response if len(response.split()) < 6 else response[:50]\n",
    "\n",
    "            ## validation using manager prompt (for which responses?)\n",
    "            # full_validation = f\"{validation_prompt} \\n{response}\"\n",
    "            # # Validate and store the response using the third prompt\n",
    "            # final_output = model.invoke(full_validation)\n",
    "            # print(\"final_output:\", final_output)\n",
    "\n",
    "process_input(doc_list, json_data)\n",
    "print(json.dumps(json_data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython Raw)",
   "language": "python",
   "name": "xpython-raw"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
